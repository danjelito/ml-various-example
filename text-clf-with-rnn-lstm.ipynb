{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "from gensim.models import FastText\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "\n",
    "def decontracted(text):\n",
    "    \"\"\"\n",
    "    Expand common contractions in a text.\n",
    "    \"\"\"\n",
    "    # specific\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"ain\\'t\", \"are not\", text)\n",
    "    text = re.sub(r\"shan\\'t\", \"shall not\", text)\n",
    "    text = re.sub(r\"ma\\'am\", \"maam\", text)\n",
    "    text = re.sub(r\"y\\'all\", \"you all\", text)\n",
    "\n",
    "    # general\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_urls(text):\n",
    "    \"\"\"\n",
    "    Remove all URLs from the text and replace them with 'URL'.\n",
    "    This function detects URLs starting with http, https, ftp, or www.\n",
    "    \"\"\"\n",
    "    # Pattern to detect URLs that start with http, https, ftp, www\n",
    "    url_pattern = r\"(https?:\\/\\/|ftp:\\/\\/|www\\.)?([-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*))\"\n",
    "    return re.sub(url_pattern, \"URL\", text)\n",
    "\n",
    "\n",
    "def clean_quotes(text):\n",
    "    \"\"\"\n",
    "    Remove &quot\n",
    "    \"\"\"\n",
    "    return re.sub(\"&quot\", '\"', text)\n",
    "\n",
    "\n",
    "def translate_emojis(text):\n",
    "    \"\"\"\n",
    "    Translates common text-based emojis like :) or :-D to the word 'emoji'.\n",
    "    \"\"\"\n",
    "    # Define a regex pattern to match various text-based emojis\n",
    "    emoji_pattern = r\"(:-\\)|:\\)|:-\\(|:\\(|:-D|:D|:-P|:P|:o|:O|<3|;\\)|;-\\))\"\n",
    "\n",
    "    # Replace matching emojis with the word 'emoji'\n",
    "    return re.sub(emoji_pattern, \" emoji \", text)\n",
    "\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    \"\"\"\n",
    "    Remove punctuations.\n",
    "    \"\"\"\n",
    "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "\n",
    "def replace_numbers_with_text(text):\n",
    "    \"\"\"\n",
    "    Replace all numbers (including ordinals like 13th) with the word 'number'.\n",
    "    \"\"\"\n",
    "    # Pattern to match numbers (both plain numbers and ordinals)\n",
    "    number_pattern = r\"\\d+(?:st|nd|rd|th)?\\b\"\n",
    "\n",
    "    # Replace all matches with the word 'number'\n",
    "    return re.sub(number_pattern, \" number \", text)\n",
    "\n",
    "\n",
    "def remove_bom(text):\n",
    "    \"\"\"\n",
    "    Remove the Byte Order Mark (BOM) if it exists in the text.\n",
    "    \"\"\"\n",
    "    return text.replace(\"\\ufeff\", \"\")\n",
    "\n",
    "\n",
    "def remove_non_standard_characters(text):\n",
    "    \"\"\"\n",
    "    Use a regular expression to remove non-standard characters.\n",
    "    \"\"\"\n",
    "    cleaned_text = re.sub(r'[^\\x20-\\x7E]+', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def clean(text):\n",
    "    \"\"\"\n",
    "    Clean a text by applying all cleaning steps.\n",
    "    \"\"\"\n",
    "    text = remove_bom(text)\n",
    "    text = decontracted(text)\n",
    "    text = translate_emojis(text)\n",
    "    text = remove_urls(text)\n",
    "    text = clean_quotes(text)\n",
    "    text = replace_numbers_with_text(text)\n",
    "    text = remove_punctuations(text)\n",
    "    text = remove_non_standard_characters(text)\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "\n",
    "def lower_doc(doc):\n",
    "    \"\"\"\n",
    "    Convert the input document to lowercase.\n",
    "    \"\"\"\n",
    "    return doc.lower()\n",
    "\n",
    "\n",
    "def tokenize_doc(doc):\n",
    "    \"\"\"\n",
    "    Tokenize the input document using NLTK word_tokenize.\n",
    "    \"\"\"\n",
    "    return tokenizer.tokenize(doc)\n",
    "\n",
    "\n",
    "def lemmatize_doc(doc):\n",
    "    \"\"\"\n",
    "    Lemmatize each token in the input document using WordNetLemmatizer.\n",
    "    \"\"\"\n",
    "    return [lemmatizer.lemmatize(token) for token in doc]\n",
    "\n",
    "\n",
    "def remove_stopwords(doc):\n",
    "    \"\"\"\n",
    "    Remove stopwords from the input document.\n",
    "    \"\"\"\n",
    "    return [token for token in doc if token not in stops]\n",
    "\n",
    "\n",
    "def remove_digit(doc):\n",
    "    \"\"\"\n",
    "    Remove tokens that consist entirely of digits.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        token\n",
    "        for token in doc\n",
    "        if not (\n",
    "            token.isdigit()\n",
    "            or token.replace(\".\", \"\").isnumeric()\n",
    "            or token.replace(\",\", \"\").isnumeric()\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "def strip_doc(doc):\n",
    "    \"\"\"\n",
    "    Strip leading and trailing whitespace from each token in the input document.\n",
    "    \"\"\"\n",
    "    return [token.strip() for token in doc]\n",
    "\n",
    "\n",
    "def remove_empty_strings(doc):\n",
    "    \"\"\"\n",
    "    Remove empty strings from the list of tokens.\n",
    "    \"\"\"\n",
    "    return [token for token in doc if token != \"''\"]\n",
    "\n",
    "\n",
    "def preprocess(doc):\n",
    "    \"\"\"\n",
    "    Preprocess a text by applying all preprocessing steps.\n",
    "    \"\"\"\n",
    "    doc = lower_doc(doc)\n",
    "    doc = tokenize_doc(doc)\n",
    "    doc = remove_stopwords(doc)\n",
    "    doc = remove_digit(doc)\n",
    "    doc = lemmatize_doc(doc)\n",
    "    doc = strip_doc(doc)\n",
    "    doc = remove_empty_strings(doc)\n",
    "    doc = [token for token in doc if len(token) > 1]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1760,), (1760,), (196,), (196,), {0.0, 1.0})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "with open(\n",
    "    \"dataset/youtube-comment-spam/Youtube-Spam-Dataset.csv\",\n",
    "    mode=\"r\",\n",
    "    encoding=\"utf-8-sig\",\n",
    ") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=\",\")\n",
    "    for i, row in enumerate(reader):\n",
    "        if i > 0:\n",
    "            raw_text = row[3]\n",
    "            label = row[-1]\n",
    "            x.append(raw_text)\n",
    "            y.append(label)\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "y = y.astype(\"float\")  # Change from int to float\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.10, random_state=42\n",
    ")\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape, set(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the data, and check the result of cleaning and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ori: Hello everyone :) I know most of you probably pass up these kind of comments, but for those who are still reading this, thanks! I don’t have any money for advertisements, no chance of getting heard, nothing... If this comes off as spam, sorry. I am a video animator, just trying to make it up into the video animation industry. Please give me the chance to prove myself to you. Please visit my channel, subscribe if you like and thumb this comment up, so everyone can see! Thank You! \n",
      "Cleaned: Hello everyone emoji I know most of you probably pass up these kind of comments but for those who are still reading this thanks I dont have any money for advertisements no chance of getting heard nothing If this comes off as spam sorry I am a video animator just trying to make it up into the video animation industry Please give me the chance to prove myself to you Please visit my channel subscribe if you like and thumb this comment up so everyone can see Thank You\n",
      "Preprocessed: ['hello', 'everyone', 'emoji', 'know', 'probably', 'pas', 'kind', 'comment', 'still', 'reading', 'thanks', 'dont', 'money', 'advertisement', 'chance', 'getting', 'heard', 'nothing', 'come', 'spam', 'sorry', 'video', 'animator', 'trying', 'make', 'video', 'animation', 'industry', 'please', 'give', 'chance', 'prove', 'please', 'visit', 'channel', 'subscribe', 'like', 'thumb', 'comment', 'everyone', 'see', 'thank']\n",
      "\n",
      "Ori: I like\n",
      "Cleaned: I like\n",
      "Preprocessed: ['like']\n",
      "\n",
      "Ori: Hey everyone check out my channel leave a like and subscribe please and if there is a song you want me to do post the name in the comments and I will get on to it(: Thanks\n",
      "Cleaned: Hey everyone check out my channel leave a like and subscribe please and if there is a song you want me to do post the name in the comments and I will get on to it Thanks\n",
      "Preprocessed: ['hey', 'everyone', 'check', 'channel', 'leave', 'like', 'subscribe', 'please', 'song', 'want', 'post', 'name', 'comment', 'get', 'thanks']\n",
      "\n",
      "Ori: subscribers please`﻿\n",
      "Cleaned: subscribers please\n",
      "Preprocessed: ['subscriber', 'please']\n",
      "\n",
      "Ori: I love song ﻿\n",
      "Cleaned: I love song\n",
      "Preprocessed: ['love', 'song']\n",
      "\n",
      "Ori: me shaking my sexy ass on my channel enjoy ^_^ ﻿\n",
      "Cleaned: me shaking my sexy ass on my channel enjoy\n",
      "Preprocessed: ['shaking', 'sexy', 'as', 'channel', 'enjoy']\n",
      "\n",
      "Ori: Is that Charlie from lost?<br />﻿\n",
      "Cleaned: Is that Charlie from lostbr\n",
      "Preprocessed: ['charlie', 'lostbr']\n",
      "\n",
      "Ori: Never gets old best song ever  ❤﻿\n",
      "Cleaned: Never gets old best song ever\n",
      "Preprocessed: ['never', 'get', 'old', 'best', 'song', 'ever']\n",
      "\n",
      "Ori: epic﻿\n",
      "Cleaned: epic\n",
      "Preprocessed: ['epic']\n",
      "\n",
      "Ori: imagine if this guy put adsense on with all these views... u could pay ur  morgage﻿\n",
      "Cleaned: imagine if this guy put adsense on with all these views u could pay ur morgage\n",
      "Preprocessed: ['imagine', 'guy', 'put', 'adsense', 'view', 'could', 'pay', 'ur', 'morgage']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_idx = np.random.randint(0, x_train.shape[0], size=10)\n",
    "for raw_text in x_train[random_idx]:\n",
    "    print(f\"Ori: {raw_text}\")\n",
    "    print(f\"Cleaned: {clean(raw_text)}\")\n",
    "    print(f\"Preprocessed: {preprocess(clean(raw_text))}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks okay so we can clean and preprocess the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_preprocessed = ([preprocess(clean(xi)) for xi in x_train])\n",
    "x_test_preprocessed = ([preprocess(clean(xi)) for xi in x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then some text will be fully erased because they contains nothing. We have to exclude such text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1756, (1756,), 196, (196,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_with_zeros = [idx for idx, sublist in enumerate(x_train_preprocessed) if len(sublist) == 0]\n",
    "x_train_preprocessed = [x for idx, x in enumerate(x_train_preprocessed) if idx not in idx_with_zeros]\n",
    "y_train = np.array([y for idx, y in enumerate(y_train) if idx not in idx_with_zeros])\n",
    "\n",
    "idx_with_zeros = [idx for idx, sublist in enumerate(x_test_preprocessed) if len(sublist) == 0]\n",
    "x_test_preprocessed = [x for idx, x in enumerate(x_test_preprocessed) if idx not in idx_with_zeros]\n",
    "y_test = np.array([y for idx, y in enumerate(y_test) if idx not in idx_with_zeros])\n",
    "\n",
    "assert len(x_train_preprocessed) == y_train.shape[0]\n",
    "assert len(x_test_preprocessed) == y_test.shape[0]\n",
    "len(x_train_preprocessed), y_train.shape, len(x_test_preprocessed), y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use fasttext to create embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(sentences=x_train_preprocessed, vector_size=20, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the embedding result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.1129637 , -0.3571668 ,  0.85003513,  0.55510575, -0.34005284,\n",
       "        0.75079966, -0.78671783, -0.13330665, -0.98105836,  0.7552863 ,\n",
       "        1.2552724 , -0.14802215,  0.14875631, -0.44608113, -0.34755653,\n",
       "        0.39965767, -0.1579542 , -0.71914256,  0.334756  , -0.30999988],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"shuffling\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can even embed full sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('verse', 0.8925649523735046),\n",
       " ('everyday', 0.8719149231910706),\n",
       " ('everyone', 0.8123201131820679),\n",
       " ('every', 0.7007248997688293),\n",
       " ('everything', 0.6893358826637268),\n",
       " ('shuffling', 0.6766314506530762),\n",
       " ('gaming', 0.6568171977996826),\n",
       " ('kind', 0.65639328956604),\n",
       " ('singing', 0.6388992071151733),\n",
       " ('also', 0.6291980743408203)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"everyday i am shuffling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we replace each word with its vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vector = [np.array([model.wv[word] for word in doc]) for doc in x_train_preprocessed]\n",
    "x_test_vector = [np.array([model.wv[word] for word in doc]) for doc in x_test_preprocessed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But then we see out input has different length (because sentences have different number of words.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(4, 20), (11, 20), (3, 20), (3, 20), (6, 20)],\n",
       " [(2, 20), (4, 20), (3, 20), (50, 20), (4, 20)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for x in x_train_vector][:5], [x.shape for x in x_test_vector][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sentence_lengths = np.array([x.shape[0] for x in x_train_vector])\n",
    "\n",
    "plt.hist(sentence_lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But they correctly have 2 dimensions (num_sentence, vector_size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert sum([len(x.shape) != 2 for x in x_train_vector]) == 0\n",
    "assert sum([len(x.shape) != 2 for x in x_test_vector]) == 0\n",
    "sum([len(x.shape) != 2 for x in x_train_vector]), sum([len(x.shape) != 2 for x in x_test_vector])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we need to add padding to each sentence. I will use max_len = 10 to make the training faster and avoid vanishing gradient problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, _ in enumerate(x_train_vector):\n",
    "    current_length = x_train_vector[i].shape[0]\n",
    "    if current_length < max_seq_length:\n",
    "        to_pad = max_seq_length - current_length\n",
    "        padding = np.zeros((to_pad, 20))  # 20 = vector dimension\n",
    "        x_train_vector[i] = np.concatenate((x_train_vector[i], padding))\n",
    "    # If there are sentences longer than max_seq_length, cut\n",
    "    else:\n",
    "        x_train_vector[i] = x_train_vector[i][:max_seq_length]\n",
    "\n",
    "\n",
    "for i, _ in enumerate(x_test_vector):\n",
    "    current_length = x_test_vector[i].shape[0]\n",
    "    if current_length < max_seq_length:\n",
    "        to_pad = max_seq_length - current_length\n",
    "        padding = np.zeros((to_pad, 20))  # 20 = vector dimension\n",
    "        x_test_vector[i] = np.concatenate((x_test_vector[i], padding))\n",
    "    # If there are sentences longer than max_seq_length, cut\n",
    "    else:\n",
    "        x_test_vector[i] = x_test_vector[i][:max_seq_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check that everything is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1756, 10, 20) (196, 10, 20) <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(1756,) (196,) <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_train_vector = np.array(x_train_vector)\n",
    "x_test_vector = np.array(x_test_vector)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(x_train_vector.shape, x_test_vector.shape, type(x_train_vector), type(x_test_vector))\n",
    "print(y_train.shape, y_test.shape, type(y_train), type(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skipped: standardization\n",
    "\n",
    "we skip this because we do minmax scaling after this so no need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now we see that the values are not standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_vector.mean(axis=(0, 1)), x_test_vector.mean(axis=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_vector.max(axis=(0, 1)), x_test_vector.max(axis=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will standardize them along the embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = x_train_vector.mean(axis=(0, 1))  # Mean of each embedding dimension (20 dims)\n",
    "# std = x_train_vector.std(axis=(0, 1))  # STD of each embedding dimension (20 dims)\n",
    "# # Avoid division by zero in case std is zero for any dimension\n",
    "# std[std == 0] = 1\n",
    "# mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_vector = (x_train_vector - mean) / std\n",
    "# x_test_vector = (x_test_vector - mean) / std\n",
    "\n",
    "# print(x_train_vector.mean(axis=(0, 1)).round(3), x_test_vector.mean(axis=(0, 1)).round(3))\n",
    "# print()\n",
    "# print(x_train_vector.std(axis=(0, 1)).round(3), x_test_vector.std(axis=(0, 1)).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMax scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each embedding dimension is standardized but the range is still too big. Let's do MinMax scaling. We'll do per dimension too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.84513998, 6.39023638, 5.42553806, 4.43172932, 3.7095015 ,\n",
       "        5.77560329, 4.13303232, 5.89650106, 5.4739666 , 2.67872977,\n",
       "        9.35178185, 5.07730675, 4.80553961, 2.57445765, 5.89524841,\n",
       "        3.28837347, 5.04882288, 4.82739353, 4.50001526, 6.05512953]),\n",
       " array([-4.43756104, -4.3689208 , -2.17692518, -2.729177  , -3.73110151,\n",
       "        -3.29433084, -6.76953125, -3.73574519, -3.16298604, -9.35859966,\n",
       "        -4.50427103, -3.47502589, -4.48545074, -4.9488802 , -3.89254761,\n",
       "        -4.42385149, -5.97787905, -4.85287809, -3.54849076, -3.48825884]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vector.max(axis=(0, 1)), x_train_vector.min(axis=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in range(x_train_vector.shape[2]):  # Iterate per dim\n",
    "    min_val = x_train_vector[:, :, dim].min()\n",
    "    max_val = x_train_vector[:, :, dim].max()\n",
    "    # for training data\n",
    "    scaled = (x_train_vector[:, :, dim] - min_val) / (max_val - min_val)\n",
    "    x_train_vector[:, :, dim] = scaled\n",
    "    # for test data\n",
    "    scaled = (x_test_vector[:, :, dim] - min_val) / (max_val - min_val)\n",
    "    x_test_vector[:, :, dim] = scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vector.max(axis=(0, 1)), x_train_vector.min(axis=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.88226577, 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.93770196, 1.        , 0.88696629, 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.92710491, 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.88071519, 0.96614983, 0.83594252]),\n",
       " array([0.        , 0.        , 0.        , 0.        , 0.05466533,\n",
       "        0.        , 0.        , 0.10832659, 0.        , 0.35784946,\n",
       "        0.        , 0.064422  , 0.0803114 , 0.        , 0.        ,\n",
       "        0.        , 0.19254625, 0.        , 0.        , 0.00739897]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_vector.max(axis=(0, 1)), x_test_vector.min(axis=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Inputs shape: torch.Size([4, 10, 20])\n",
      "Targets shape: torch.Size([4, 1])\n",
      "Inputs: tensor([[[0.5939, 0.4160, 0.3820, 0.4928, 0.5104, 0.4509, 0.6543, 0.4731,\n",
      "          0.4737, 0.7085, 0.1552, 0.3510, 0.5705, 0.5276, 0.4058, 0.7113,\n",
      "          0.6754, 0.6242, 0.5103, 0.4638],\n",
      "         [0.4283, 0.4194, 0.3380, 0.4408, 0.6264, 0.5117, 0.6756, 0.4344,\n",
      "          0.4783, 0.8067, 0.2819, 0.5016, 0.4793, 0.6792, 0.3025, 0.6388,\n",
      "          0.6543, 0.5955, 0.5583, 0.4599],\n",
      "         [0.6132, 0.4900, 0.3304, 0.2567, 0.5112, 0.3076, 0.7592, 0.3413,\n",
      "          0.4365, 0.7235, 0.3107, 0.4599, 0.5124, 0.7809, 0.3451, 0.6130,\n",
      "          0.5377, 0.5467, 0.4995, 0.3586],\n",
      "         [0.4512, 0.4081, 0.3393, 0.3725, 0.4117, 0.6108, 0.6702, 0.4066,\n",
      "          0.4506, 0.6394, 0.2784, 0.4547, 0.3714, 0.6959, 0.3641, 0.5364,\n",
      "          0.6350, 0.5983, 0.5156, 0.5478],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655]],\n",
      "\n",
      "        [[0.2862, 0.4872, 0.2660, 0.4799, 0.5023, 0.4277, 0.7958, 0.4236,\n",
      "          0.3647, 0.7490, 0.4324, 0.4368, 0.6383, 0.7638, 0.3284, 0.7010,\n",
      "          0.6853, 0.5241, 0.5168, 0.3475],\n",
      "         [0.4399, 0.3801, 0.3712, 0.3479, 0.4175, 0.3758, 0.6399, 0.3158,\n",
      "          0.3225, 0.7376, 0.4285, 0.4031, 0.5968, 0.7573, 0.3190, 0.7020,\n",
      "          0.5462, 0.4710, 0.5657, 0.3019],\n",
      "         [0.5181, 0.4280, 0.3595, 0.4845, 0.6340, 0.3624, 0.5673, 0.5194,\n",
      "          0.4041, 0.7186, 0.2913, 0.4876, 0.5034, 0.6406, 0.4104, 0.6035,\n",
      "          0.4761, 0.4042, 0.6013, 0.3164],\n",
      "         [0.4420, 0.6190, 0.3338, 0.4845, 0.6147, 0.1866, 0.7314, 0.5142,\n",
      "          0.2573, 0.7452, 0.3787, 0.4979, 0.3457, 0.9526, 0.3440, 0.3623,\n",
      "          0.5123, 0.4167, 0.4754, 0.4078],\n",
      "         [0.5181, 0.4280, 0.3595, 0.4845, 0.6340, 0.3624, 0.5673, 0.5194,\n",
      "          0.4041, 0.7186, 0.2913, 0.4876, 0.5034, 0.6406, 0.4104, 0.6035,\n",
      "          0.4761, 0.4042, 0.6013, 0.3164],\n",
      "         [0.5088, 0.4112, 0.5115, 0.2204, 0.7191, 0.5494, 0.5252, 0.6378,\n",
      "          0.2737, 0.5275, 0.3926, 0.3756, 0.6114, 0.4599, 0.2674, 0.7903,\n",
      "          0.2145, 0.4062, 0.7448, 0.3559],\n",
      "         [0.6551, 0.5132, 0.2625, 0.4750, 0.7882, 0.4442, 0.5104, 0.6278,\n",
      "          0.1507, 0.5543, 0.3484, 0.5257, 0.5062, 0.6004, 0.2898, 0.5345,\n",
      "          0.3321, 0.3671, 0.8477, 0.1052],\n",
      "         [0.5181, 0.4280, 0.3595, 0.4845, 0.6340, 0.3624, 0.5673, 0.5194,\n",
      "          0.4041, 0.7186, 0.2913, 0.4876, 0.5034, 0.6406, 0.4104, 0.6035,\n",
      "          0.4761, 0.4042, 0.6013, 0.3164],\n",
      "         [0.4392, 0.3866, 0.3562, 0.6267, 0.5925, 0.4018, 0.6109, 0.4251,\n",
      "          0.5794, 0.7288, 0.4330, 0.4771, 0.7831, 0.4865, 0.5013, 0.2513,\n",
      "          0.5761, 0.3105, 0.5932, 0.4213],\n",
      "         [0.4152, 0.4897, 0.5902, 0.0000, 0.5884, 0.6723, 0.5642, 0.5450,\n",
      "          0.2352, 0.5231, 0.4315, 0.5795, 0.7633, 0.3595, 0.2835, 0.9518,\n",
      "          0.1925, 0.3924, 0.6524, 0.1764]],\n",
      "\n",
      "        [[0.5939, 0.4160, 0.3820, 0.4928, 0.5104, 0.4509, 0.6543, 0.4731,\n",
      "          0.4737, 0.7085, 0.1552, 0.3510, 0.5705, 0.5276, 0.4058, 0.7113,\n",
      "          0.6754, 0.6242, 0.5103, 0.4638],\n",
      "         [0.5939, 0.4160, 0.3820, 0.4928, 0.5104, 0.4509, 0.6543, 0.4731,\n",
      "          0.4737, 0.7085, 0.1552, 0.3510, 0.5705, 0.5276, 0.4058, 0.7113,\n",
      "          0.6754, 0.6242, 0.5103, 0.4638],\n",
      "         [0.7849, 0.2732, 0.2780, 0.3936, 0.5899, 0.6063, 0.5298, 0.2623,\n",
      "          0.4899, 0.8392, 0.3889, 0.0753, 0.4334, 0.6781, 0.4058, 0.6119,\n",
      "          0.6692, 0.6532, 0.7477, 0.3752],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655]],\n",
      "\n",
      "        [[0.6132, 0.4900, 0.3304, 0.2567, 0.5112, 0.3076, 0.7592, 0.3413,\n",
      "          0.4365, 0.7235, 0.3107, 0.4599, 0.5124, 0.7809, 0.3451, 0.6130,\n",
      "          0.5377, 0.5467, 0.4995, 0.3586],\n",
      "         [0.4900, 0.4421, 0.3707, 0.3256, 0.5264, 0.2763, 0.6594, 0.3925,\n",
      "          0.3917, 0.7250, 0.3867, 0.4557, 0.4499, 0.7189, 0.4199, 0.5897,\n",
      "          0.5716, 0.4589, 0.5339, 0.3873],\n",
      "         [0.4557, 0.4122, 0.3419, 0.3886, 0.5074, 0.3114, 0.5847, 0.3451,\n",
      "          0.3822, 0.8312, 0.3905, 0.3820, 0.4692, 0.7638, 0.4649, 0.7153,\n",
      "          0.6342, 0.5826, 0.4147, 0.2775],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655],\n",
      "         [0.4780, 0.4061, 0.2863, 0.3811, 0.5015, 0.3632, 0.6209, 0.3878,\n",
      "          0.3662, 0.7775, 0.3251, 0.4063, 0.4828, 0.6578, 0.3977, 0.5736,\n",
      "          0.5421, 0.5013, 0.4409, 0.3655]]])\n",
      "Targets: tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            self.texts[index].astype(\"float32\"), \n",
    "            self.labels[index].reshape(-1).astype(\"float32\")\n",
    "        )\n",
    "\n",
    "train_dataset = TextDataset(x_train_vector, y_train)\n",
    "test_dataset = TextDataset(x_test_vector, y_test)\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "for batch_idx, (inputs, targets) in enumerate(train_dataloader):\n",
    "    print(f\"Batch {batch_idx + 1}\")\n",
    "    print(f\"Inputs shape: {inputs.shape}\")  # Should be (batch_size, sequence_length, embedding_dim)\n",
    "    print(f\"Targets shape: {targets.shape}\")  # Should be (batch_size, 1)\n",
    "    print(\"Inputs:\", inputs)\n",
    "    print(\"Targets:\", targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5269],\n",
      "        [0.5271],\n",
      "        [0.5268],\n",
      "        [0.5268]]) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_stacked_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_stacked_layers = num_stacked_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_stacked_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.linear = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "\n",
    "    def forward(self, xs):\n",
    "        batch_size = xs.shape[0]\n",
    "        h0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size)\n",
    "        output, hidden = self.lstm(xs, (h0, c0))\n",
    "        output = self.linear(output[:, -1, :])\n",
    "        output = torch.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "lstm = LSTM(input_size=20, hidden_size=64, num_stacked_layers=2)\n",
    "\n",
    "# test if our model is working\n",
    "with torch.no_grad():\n",
    "    print(lstm(inputs), lstm(inputs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6947, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "loss = criterion(lstm(inputs), targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate loss manually to make sure the loss calculation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.52686626],\n",
       "        [0.5270515 ],\n",
       "        [0.5267923 ],\n",
       "        [0.52682626]], dtype=float32),\n",
       " array([[1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.]], dtype=float32))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = lstm(inputs).detach().numpy()\n",
    "targets = targets.numpy() \n",
    "preds, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6947"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bceloss(preds, targets, epsilon=1e-12):\n",
    "    \"\"\"\n",
    "    Compute Binary Cross-Entropy (BCE) loss between predictions and targets.\n",
    "    \"\"\"\n",
    "    # Clip predictions to avoid log(0) error\n",
    "    preds = np.clip(preds, epsilon, 1 - epsilon)\n",
    "    # Compute the binary cross-entropy loss\n",
    "    loss = -np.sum(targets * np.log(preds) + (1 - targets) * np.log(1 - preds)) / len(\n",
    "        targets\n",
    "    )\n",
    "\n",
    "    return loss.round(4)\n",
    "\n",
    "\n",
    "assert(bceloss(preds, targets).round(4) == round(loss.item(), 4))\n",
    "bceloss(preds, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.6934, Train Accuracy: 0.5046, Validation Loss: 0.6905, Validation Accuracy: 0.6071\n",
      "Epoch [2/10], Train Loss: 0.6913, Train Accuracy: 0.5416, Validation Loss: 0.6951, Validation Accuracy: 0.4184\n",
      "Epoch [3/10], Train Loss: 0.5389, Train Accuracy: 0.7306, Validation Loss: 0.4001, Validation Accuracy: 0.8214\n",
      "Epoch [4/10], Train Loss: 0.3891, Train Accuracy: 0.8405, Validation Loss: 0.3752, Validation Accuracy: 0.8214\n",
      "Epoch [5/10], Train Loss: 0.3769, Train Accuracy: 0.8485, Validation Loss: 0.3749, Validation Accuracy: 0.8214\n",
      "Epoch [6/10], Train Loss: 0.3706, Train Accuracy: 0.8554, Validation Loss: 0.3814, Validation Accuracy: 0.8214\n",
      "Epoch [7/10], Train Loss: 0.3660, Train Accuracy: 0.8536, Validation Loss: 0.3867, Validation Accuracy: 0.8163\n",
      "Epoch [8/10], Train Loss: 0.3620, Train Accuracy: 0.8548, Validation Loss: 0.3907, Validation Accuracy: 0.8163\n",
      "Epoch [9/10], Train Loss: 0.3583, Train Accuracy: 0.8565, Validation Loss: 0.3936, Validation Accuracy: 0.8214\n",
      "Epoch [10/10], Train Loss: 0.3548, Train Accuracy: 0.8593, Validation Loss: 0.3953, Validation Accuracy: 0.8214\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=lr)\n",
    "epochs = 10\n",
    "print_step = 1\n",
    "\n",
    "\n",
    "def calculate_accuracy(outputs, targets):\n",
    "    predicted = (outputs >= 0.5).float()\n",
    "    correct = (predicted == targets).sum().item()  # Count correct predictions\n",
    "    return correct / len(targets)  # Return accuracy as a fraction\n",
    "\n",
    "\n",
    "def train_one_epoch():\n",
    "    lstm.train()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    for batch_idx, (xs, ys) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = lstm(xs)\n",
    "        loss = criterion(outputs, ys)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        accuracy = calculate_accuracy(outputs, ys)\n",
    "        running_accuracy += accuracy\n",
    "    return running_loss / (batch_idx + 1), running_accuracy / (batch_idx + 1)\n",
    "\n",
    "\n",
    "def val_one_epoch():\n",
    "    lstm.eval()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (xs, ys) in enumerate(test_dataloader):\n",
    "            outputs = lstm(xs)\n",
    "            loss = criterion(outputs, ys)\n",
    "            running_loss += loss.item()\n",
    "            accuracy = calculate_accuracy(outputs, ys)\n",
    "            running_accuracy += accuracy\n",
    "    return running_loss / (batch_idx + 1), running_accuracy / (batch_idx + 1)\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training step\n",
    "    train_loss, train_accuracy = train_one_epoch()\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Validation step\n",
    "    test_loss, test_accuracy = val_one_epoch()\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Print training and validation loss and accuracy\n",
    "    if (epoch + 1) % print_step == 0:\n",
    "        print(\n",
    "            f\"Epoch [{epoch + 1}/{epochs}], \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
    "            f\"Validation Loss: {test_loss:.4f}, Validation Accuracy: {test_accuracy:.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(train_losses)), train_losses)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7353],\n",
      "        [0.0798],\n",
      "        [0.7776],\n",
      "        [0.0854]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_idx, (xs, ys) in enumerate(train_dataloader):\n",
    "        outputs = lstm(xs)\n",
    "        print(outputs)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We succeed in training the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text: Charlie from LOST?﻿\n",
      "Preprocessed text: ['charlie', 'lost']\n",
      "True vs  predicted label: 0.0 vs 0.0\n",
      "Prediction is CORRECT.\n",
      "\n",
      "Raw text: BEST SONG EVER X3333333333﻿\n",
      "Preprocessed text: ['best', 'song', 'ever', 'number']\n",
      "True vs  predicted label: 0.0 vs 0.0\n",
      "Prediction is CORRECT.\n",
      "\n",
      "Raw text: Aslamu Lykum... From Pakistan﻿\n",
      "Preprocessed text: ['aslamu', 'lykum', 'pakistan']\n",
      "True vs  predicted label: 0.0 vs 1.0\n",
      "Prediction is INCORRECT.\n",
      "\n",
      "Raw text: I absolutely adore watching football plus I’ve started earning income with out risk from claiming bonus deals. It’s a weird technique where you put money on something with one bookmakers and put money against it on Betfair. You acquire the bonus as income . A lad named Jim Vanstone is selecting the wagers free on his website Vanstone Secrets (Google it!). I have generated about 600 quid so far. And it’s free. I assume the bookmakers pay him to get new men and women, but it succeeds.\n",
      "Preprocessed text: ['absolutely', 'adore', 'watching', 'football', 'plus', 'ive', 'started', 'earning', 'income', 'risk', 'claiming', 'bonus', 'deal', 'weird', 'technique', 'put', 'money', 'something', 'one', 'bookmaker', 'put', 'money', 'betfair', 'acquire', 'bonus', 'income', 'lad', 'named', 'jim', 'vanstone', 'selecting', 'wager', 'free', 'website', 'vanstone', 'secret', 'google', 'generated', 'number', 'quid', 'far', 'free', 'assume', 'bookmaker', 'pay', 'get', 'new', 'men', 'woman', 'succeeds']\n",
      "True vs  predicted label: 0.0 vs 1.0\n",
      "Prediction is INCORRECT.\n",
      "\n",
      "Raw text: I really love this video.. http://www.bubblews.com/account/389088-sheilcen﻿\n",
      "Preprocessed text: ['really', 'love', 'video', 'url']\n",
      "True vs  predicted label: 0.0 vs 1.0\n",
      "Prediction is INCORRECT.\n",
      "\n",
      "Raw text: BEAUTIFUL\n",
      "Preprocessed text: ['beautiful']\n",
      "True vs  predicted label: 0.0 vs 0.0\n",
      "Prediction is CORRECT.\n",
      "\n",
      "Raw text: Hey plz check out my music video. Thanks!! :-)﻿\n",
      "Preprocessed text: ['hey', 'plz', 'check', 'music', 'video', 'thanks', 'emoji']\n",
      "True vs  predicted label: 1.0 vs 1.0\n",
      "Prediction is CORRECT.\n",
      "\n",
      "Raw text: Look and shares my video please :D\n",
      "Preprocessed text: ['look', 'share', 'video', 'please', 'emoji']\n",
      "True vs  predicted label: 1.0 vs 1.0\n",
      "Prediction is CORRECT.\n",
      "\n",
      "Raw text: this song sucks﻿\n",
      "Preprocessed text: ['song', 'suck']\n",
      "True vs  predicted label: 0.0 vs 0.0\n",
      "Prediction is CORRECT.\n",
      "\n",
      "Raw text: Go to my channel if u want to see a fly getting burned alive﻿\n",
      "Preprocessed text: ['go', 'channel', 'want', 'see', 'fly', 'getting', 'burned', 'alive']\n",
      "True vs  predicted label: 1.0 vs 1.0\n",
      "Prediction is CORRECT.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assert x_test_vector.shape[0] == len(x_test_preprocessed)\n",
    "assert len(x_test) == len(x_test_preprocessed)\n",
    "\n",
    "# Iterate through the test data\n",
    "for i, (vector, clean_text, raw_text, label) in enumerate(\n",
    "    zip(x_test_vector, x_test_preprocessed, x_test, y_test)\n",
    "):\n",
    "    # Reshape the vector and convert to a PyTorch tensor\n",
    "    vector = torch.from_numpy(vector.reshape(1, 10, 20).astype(\"float32\"))\n",
    "\n",
    "    # Get the model prediction\n",
    "    pred = lstm(vector).detach().item()\n",
    "    pred_label = (pred >= 0.5) * 1.0\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Raw text: {raw_text}\")\n",
    "    print(f\"Preprocessed text: {clean_text}\")\n",
    "    print(f\"True vs  predicted label: {pred_label} vs {label}\")\n",
    "    if pred_label == label:\n",
    "        print(\"Prediction is CORRECT.\")\n",
    "    else:\n",
    "        print(\"Prediction is INCORRECT.\")\n",
    "\n",
    "    print()\n",
    "\n",
    "    # Limit to the first 10 predictions\n",
    "    if i + 1 == 10:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
